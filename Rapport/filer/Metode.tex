\chapter{Metode}\label{chap:Metode}
%%%%%%%%%% System system %%%%%%%%%%
\section{Systemflow}
CrustCrawleren påbegynder arbejdsprocessen ved at gå til en defineret udgangsposition. Denne er lodret opretstående.
Derefter tages et billede med kameraet, der er monteret ca. én meter over bordet som CrustCrawleren er monteret på.
Vision systemet analyserer billedet og finder centrum på de opstillede klodser inden for arbejdsområdet.
Positionen sendes herefter til CrustCrawleren, hvorefter den bevæger sig til dinne.
Når CrustCrawleren har nået positionen aflæses trykket på tryksensoren.
Sålænge trykket ikke overstiger en fast grænseværdi fortsætter grabberen med at lukke sig.
Så snart trykket når grænseværdien bevæger CrustCrawleren sig til spejlingspositionen i spejlingsområdet og åbner grabberen.
Denne process itereres, indtil der ikke kan findes klodser i arbejdsområdet.
Når CrustCrawleren ikke registrerer flere klodser bevæger den sig til en håndtryksposition, hvor den afventer et tryk i grabberen, hvorefter programmet afsluttes.
Figur \vref{fig:Flowchart} viser et flowchartdiagram over handlingsforløbet i main funktionen.
\figur{1}{Flowchart}{Flow chart main}{fig:Flowchart}
 
%%%%%%%%%% Main system %%%%%%%%%%
\section{Main system}
I main tråden startes der med at initialisere og abonnere på VisionPublisher noden, se bilag \vref{app:PythonKode} for fuld Python kode for main funktionen.
Dette gøres i \texttt{setUpVisionCoordinates} funktionen.
Der abonneres også på tryksensor noden i \texttt{setupGrabberPressureSensor} funktionen.

Efter dette anvendes \texttt{RobotDo} funktionen til at flytte CrustCrawleren til udgangspositionen.
CrustCrawleren er nu klar til at påbegynde arbejdsprocessen.
Dette gøres ved at kalde \texttt{main} funktionen.

I \texttt{main} funktionen bestemmer en while-løkke, hvorvidt der fortsættes med at arbejde.
While-løkken fortsætte sålænge jobbet er aktivt.
I while-løkken hentes koordinaterne.
Hvis koordinaternes længde er over 0, og dermed findes, kaldes \texttt{mirrorCube} metoden med koordinaterne.
\texttt{mirrorCube} flytter klodsen til den spejlede position.
Er længden på koordinaterne ikke over 0, flyttes CrustCrawleren til håndtrkspositionen hvor jobbet først afsluttes når tryksensoren modtager et tryk.

Nedenfor ses et sekvensdiagram af main programmet:
\figur{1}{MainSequenceDiagram}{Main sekvens diagram}{fig:MainSequenceDiagram}


%%%%%%%%%% Vision system %%%%%%%%%%
\newpage
\section{Vision system}
Vision systemet i dette projekt har til formål at finde positionen af hver klods, der skal flyttes af CrustCrawleren.
Dette gøre ved brug af billeder taget med et webcam monteret ca. 1 m over det bord, CrustCrawleren er monteret på.
For at finde positionerne af klodserne oprettes en maske, der fjerner alt på billederne undtagen klodserne med en bestemt farve.
Masken oprettes ved at lede efter farver inden for fastsatte grænseværdier og fjerne farver, der ikke ligger inden for disse.
MATLAB applikationen Color Thresholder bruges til at bestemme hvilket colorspace der skal arbejdes i og hvilke grænseværdier der identificerer klodserne.
Til udvikling af vision noden i Python bruges funktioner fra OpenCV, som indeholder algoritmer relateret til computer vision.

%%%%% Vision node %%%%%
\subsection{Vision node}
For at CrustCrawleren kan vide, hvor klodserne er, skal den have et x,y koordinat på klodsernes centrum.
Derfor er en ROS node publisher, som publishere koordinaterne, konstrueret, se nedenstående kode for den fulde kode for vison noden.
Først bliver en ROS publisher lavet, på topic'et \texttt{Coordinates} og data typen på messagen er string.
Derefter bliver en ROS node lavet med navnet \texttt{VisionPublisher}.
Publiceringsfrekvensen initialiseres til 1 hz, dvs. at der bliver publisheret hvert sekund. \newline
Funktionen \texttt{find\_brick\_centers} kaldes, hvilken returnerer x,y koordinaterne på alle klodserne, der er i arbejdsområdet, i et array.
Derefter bliver plads 0 og 1 i arrayet, som er x og y koordinater på den første klods, lagt ind i en string og derefter publisheret.
Hvis der ikke er nogle klodser i arbejdsområdet bliver der sendt en tom string.

\begin{lstlisting}[language=Python]
#!/usr/bin/env python

import rospy
from findBricks import *
from std_msgs.msg import String

def VisionPublisher():
    
    pub = rospy.Publisher('Coordinates', String, queue_size=10)
    rospy.init_node('VisionPublisher', anonymous=True)
    rate = rospy.Rate(1) # 1hz
    while not rospy.is_shutdown():
        try:
            bricks = find_brick_centers()
            
            if len(bricks) != 0:        
                coords_str = "%f,%f"%(bricks[0], bricks[1])
            else:
                coords_str = "%f,%f"%(0, 0)          
            pub.publish(coords_str)
            
            print("Test af coords_str")
            print(coords_str)
        except:
            print "Error"
        rate.sleep()

if __name__ == '__main__':
    try:
        VisionPublisher()
    except rospy.ROSInterruptException:
        pass
\end{lstlisting}

%%%%% MATLAB - Color Thresholder %%%%%
\newpage
\subsection{MATLAB - Color Thresholder}
MATLAB's  applikation Color Thresholder er anvendt til at bestemme, hvilket color space og hvilke grænseværdier, der er mest optimale til at identificere de farvede klodser med kameraet.

I Color Thresholder indlæses et billede, hvorpå en klods af hver farve er repræsenteret.
Valget af color space baseres på, hvor klodserne adskiller sig mest fra bordpladen, da bordpladen skal fjernes med den oprettede maske.
På figur \ref{fig:ColorThresholderColorSpace} ses det, at der i color spacet HSV (Hue, Saturation, Value) er størst kontrast mellem klodser og bordplade.
Det vælges derfor at arbejde i color spacet HSV.

\figur{0.75}{ColorThresholderColorSpace.pdf}{MATLAB's applikation Color Thresholder til identifikation af optimalt color space. Den røde firkant viser, hvor der er stor kontrast mellem klodser og bordplade.}{fig:ColorThresholderColorSpace}

Color Thresholder bruges derefter til at finde grænseværdierne til hhv. H, S og V kanalerne, til identifikation af de forskelligt farvede klodser, ved at ændre på H, S og V kanalerne.
Figur \vref{fig:ColorThresholderBlue} er et eksempel på grænseværdierne til identifikation af den blå klods.

\figur{0.8}{ColorThresholderBlue.pdf}{Identifikation af blå klods i MATLAB's applikation Color Thresholder i color space HSV.}{fig:ColorThresholderBlue}

For hver farve blev følgende grænseværdier identificeret (se bilag \vref{app:MATLABVision} for funktioner til identifikation af hver farve):
\begin{table}[H]
\centering
\begin{tabular}{l|l|l|l}
Farve	&	H			&	S			&	V\\
\hline
Blå		&	0.515-0.790	&	0.300-1.000	&	0.400-1.000\\
Rød		&	0.900-0.080	&	0.300-1.000	&	0.000-1.000\\
Grøn	&	0.200-0.415	&	0.300-1.000	&	0.000-1.000\\
Gul		&	0.115-0.210	&	0.300-1.000	&	0.400-1.000\\
\end{tabular}	
\caption{Grænseværdier til identifikation af de fire farver, blå, rød, grøn og gul. MATLAB range 0-1.}
\end{table}

Det ses på figur \vref{fig:ColorThresholderBlue}, at nogle områder uden for bordpladen ikke forsvinder fuldstændig ved denne segmentering, da de har farver, der ligger tæt på den blå klods'.
Dette løses ved at beskære billedet således, at kun bordpladen vises på billedet.
Derudover skal der kun identificeres klodser på højre side af CrustCrawleren, hvorfor billedet beskæres yderligere, så kun det relevante område vises.

Figur \vref{fig:ColorThresholderResult} viser resultatet af MATLAB analysen, som beskærer billedet og identificerer klodser i de fire farver, blå, rød, grøn og gul.
Se bilag \vref{app:MATLABVision} for script og funktioner brugt i analysen.
Det ses også på figur \ref{fig:ColorThresholderResult}, at det vil være nødvendigt at implementere en grænseværdi for, hvor store områder, der skal identificeres som klodser, da der er små områder, der ikke forsvinder helt ved segmenteringen.

\figur{1}{ColorThresholderResult.pdf}{Resultat af MATLAB analysen}{fig:ColorThresholderResult}

%%%%% Vision med OpenCV-Python %%%%%
\newpage
\subsection{Vision med OpenCV-Python}
Vision funktionerne, \texttt{find\_brick\_centers}, \texttt{get\_from\_webcam},\newline \texttt{extract\_single\_color\_range}, \texttt{threshold\_image}, \texttt{contours} og \texttt{get\_centers}, er udviklet i Python med det formål at identificere klodsernes placering.
Dette gøres ved at finde centrum af de klodser, der identificeres ved brug af en oprettet maske.
Den identificerer klodserne, én farve af gangen, og samler til sidst centrum for alle fundne klodser for alle fire farver i et array.

\texttt{find\_brick\_centers} er main funktionen til at finde centrum af klodserne, se bilag \vref{app:PythonKode} for fuld Python kode for vision funktionerne.
Funktionen starter med at definere grænseværdierne for farverne.
OpenCV's range i HSV color spacet er ikke det samme som MATLAB's, hvorfor værdierne fundet i MATLAB skal konverteres:
\begin{table}[H]
\centering
\begin{tabular}{l|l}
H		&	0-179\\
\hline
S		&	0-255\\
\hline
V		&	0-255\\
\end{tabular}	
\caption{Range for kanalerne H, S og V i OpenCV-Python}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{l|l|l|l}
Farve	&	H			&	S			&	V	\\
\hline
Blå		&	92-141		&	76-255	&	102-255	\\
Rød		&	161-14		&	76-255	&	0-255	\\
Grøn	&	36-74		&	76-255	&	0-255	\\
Gul		&	21-38		&	76-255	&	102-255	\\
\end{tabular}	
\caption{Grænseværdier konverteret fra MATLAB range til OpenCV-Python range og afrundet til heltal.}
\end{table}

Derudover skal H grænseværdierne for den røde klods deles op i to intervaller; 0-14 og 161-179.

Efter at have defineret grænseværdierne kaldes metoden \texttt{get\_from\_webcam}. Denne indlæser et billede fra kameraet og beskærer det, så kun det relevante område vises på billedet.

Billedet fra \texttt{get\_from\_webcam} konverteres fra color spacet BGR til HSV ved brug af OpenCV funktionen \texttt{cv2.cvtCOLOR}.
Efter konverteringen kaldes funktionerne\newline \texttt{extract\_single\_color\_range}, \texttt{threshold\_image},\newline \texttt{contours} og \texttt{get\_centers} på billedet for hver farve.

\texttt{extract\_single\_color\_range} opretter en maske og fjerner alle farver på billedet, som ikke ligger i den specificerende grænseværdi, se bilag \ref{app:VisionPrincipper} afsnit \vref{sec:Masker} for en beskrivelse af princippet i en maske.
Maksen oprettes ved brug af OpenCV funktionen \texttt{cv2.inRange}.
Funktionen returnerer billedet, hvor kun farver inden for den specificerede grænseværdi er synlige.

Funktionen \texttt{threshold\_image} thresholder billedet med OpenCV funktionen \texttt{cv2.threshold} og udfører morfologiske operationer på det.
Den udfører en \textit{dialate} med OpenCV funktionen \texttt{cv2.dilate} for at lukke små huller og en

\begin{wrapfigure}{r}{0.3\textwidth}
  \begin{center}
    \includegraphics[width=0.23\textwidth]{figurer/ImagesFromVision}
  \end{center}
  \caption{Illustration af vision algoritmen}\label{fig:ImagesFromVision}
\end{wrapfigure}

\textit{close}, med OpenCV funktionen \texttt{cv2.morphologyEx}, for at lukke evt. brudte kanter, se bilag \ref{app:VisionPrincipper} afsnit \vref{sec:Morphologi} for en beskrivelse af princippet i de morfologiske operationer.

\texttt{contours} konverterer det returnerede billede fra\newline \texttt{threshold\_image} til et gråskalabillede ved brug af OpenCV funktionen \texttt{cv2.cvtColor}.
Derefter identificerer den konturer på billedet ved brug af OpenCV funktionen \texttt{cv2.findContours}.
Funktionen returnerer disse konturer.

Funktionen \texttt{get\_centers} finder, for hver kontur, en firkantet repræsentation af konturen ved brug af OpenCV funktionerne \texttt{cv2.arcLength} og \texttt{cv2.approxPolyDP} og finder derefter arealet af disse ved brug af OpenCV funktionen \texttt{cv2.contourArea}.
Hvis dette areal er større end 500 pixels anses området som værende en klods og et vægtet gennemsnit af områdets pixels (momentet) findes ved brug af OpenCV cv2.moments.
Centrum koordinaterne (række og kolonne i billedet) for momentet findes og returneres. 

Da koordinatsættet, returneret fra \texttt{get\_centers}, er i pixels, en række og en kolonne i billedet, skal det konverteres til koordinater i CrustCrawlerens koordinatsystem.
Se figur \vref{fig:ConvertCoordinate} for en illustration af de to koordinatsystemer.
For at identificere, hvor mange pixels, der er pr. enhed i CrustCrawlerens koordinatsystem, udføres en test, hvor klodser sættes i et kendte punkter i CrustCrawlerens koordinatsystem.
Derefter tages et billede med kameraet og klodsernes koordinater i pixels identificeres via. vision algoritmerne.
Se bilag \vref{app:KoordinatsystemKonvertering} for den fulde test.
Testen viste, at der var 9 pixels pr. enhed i CrustCrawlerens koordinatsystem.
\textit{x\_robot} aksen og \textit{row} aksen vender hver sin vej og har origo i hver sit hjørne af billedet.
På grund af dette trækkes pixel-koordinatets rækkeværdi fra højden af billedet i pixels før det divideres med de 9 pixels pr. enhed for at vende aksen om.
Dermed returnerer \texttt{find\_brick\_centers} centrum i CrustCrawlerens koordinatsystem for alle klodser identificeret af vision aloritmerne.
\figur{0.8}{ConvertCoordinate}{CrustCrawlerens koordinatsystem i forhold til række og kolonne koordinatsystemet for billedet.}{fig:ConvertCoordinate}

%%%%%%%%%% Robot system %%%%%%%%%%
\newpage
\section{Robot system}
%%%%%%%%%% Links og joints %%%%%%%%%%
\subsection{Links og joints}
CrustCrawleren består af en række links og joints. Disse er bestemt vha. opmåling af selve robotten. 

\figur{1}{crustCrawlerLinks.png}{Figur over links på crustcrawler}{fig:crustCrawlerLinks}

Som det ses på figur \ref{fig:crustCrawlerLinks}, består CrustCrawleren af fire links. CrustCrawlerens base roterer. Derudover kan to led på CrustCrawlerens arm bøje. Slutteligt kan grabberen rotere. Det kan deraf udledes, at CrustCrawleren består af fire revolute joints og dermed besidder fire frihedsgrader. Dette medfører visse begrænsninger i CrustCrawlerens arbejdsområde, da seks frihedsgrader er nødvendige for at opnå fuld frihed inden for arbejdsområdet.

%%%%%%%%%% Coordinate frames %%%%%%%%%%
\subsection{Coordinate frames}
Til at bestemme koordinatrammerne for CrustCrawleren, er Denavit-Hartenberg konventionen anvendt til at udlede DH parametre for CrustCrawleren, se bilag \vref{app:DenavitHartenberg} for princippet bag Denavit-Hartenberg konventionen. Dette indebærer at konstruere et koordinatsæt for hver joint oven på hinanden. 

\figur{0.60}{crustCrawlerCoordinateFrames.png}{Figur over coordinate frames på crustcrawler}{fig:crustCrawlerLinks}

Med koordinatrammerne og informationer om links kan Denavit Hartenberg parametrene findes. 

\begin{table}[H]
\centering
\begin{tabular}{l|l|l|l|l}
Links	&	$\theta$ (deg) 	&	d(cm)		&	a(cm)		& 	$\alpha$ (deg)\\
\hline
1		&	$\theta$1			&	16.8			&	0			&	90\\
2		&	$\theta$2			&	0			&	17.31		&	0\\
3		&	$\theta$3			&	0			&	0			&	90\\
4		&	$\theta$4			&	20		&	0			&	0\\
\end{tabular}	
\caption{DH parametre for CrustCrawleren.}
\end{table}

For dybere gennemgang af tildeling af koordinatrammer og udledning af parametre henvises til appendix \vref{app:DenavitHartenberg}.

%%%%%%%%%% Invers kinematik %%%%%%%%%%
\subsection{Invers kinematik}
CrustCrawleren skal kunne bevæge sig hen til en given position ud fra et koordinatsæt. Da motorerne på crustcrawleren styres ud fra vinkler skal en matematisk konventering fra koordinatsæt til vinkler foretages.\newline
Først skal længderne af CrustCrawlerens links bestemmes:
\begin{align}
	d_1&=16.8	&	a_1&=0\\
	d_4&=20		&	a_2&=17.31
\end{align}

Vinklen i joint 1 ($q_1$) beregnes ud fra x og y koordinatet:
\begin{equation}
	q_1=atan\left(\frac{y}{x}\right)
\end{equation}
Derefter kan vinklen i joint 2 ($q_2$) og joint 3 ($q_3$) bestemmes.
Først skal $q_3$ bestemmes før at $q_2$ kan findes, da den bruges i udregningen.
\begin{gather}
	r_2=\left(x-a_1\cdot cos(q_1)\right)^2+\left(y-a_1\cdot sin(q_1)\right)^2\\
	s=z-d_1\\
	d=\frac{r_2+s^2-a_2^2-d_4^2}{2\cdot a_2\cdot d_4}\\
	q_3=atan\left(\frac{-\sqrt{1-d^2}}{d}\right)\\
	q_2=atan\left(\frac{s}{\sqrt{r_2}-atan\left(\frac{d_4\cdot sin(q_3)}{a_2+d_4\cdot cos(q_3)}\right)-\frac{\pi}{2}}\right)
\end{gather}
Overstående formler er blevet implementeret i python kode se \vref{sec:InvRobot}

%%%%%%%%%% RobotExecute %%%%%%%%%%
\subsection{RobotExecute}
Klassen \texttt{RobotExecute} håndterer konstruktionen og afsendelsen af kommandoer til CrustCrawleren. Det er denne klasse, der står for at igangsætte CrustCrawlerens bevægelser. Dette gøres vha. ROSPY bibliotekets \texttt{SimpleActionClient}.

Først opbygges et array af navnene på de enkelte led. Derefter opbygges et array der indeholder de enkelte leds position bestående af de tre vinkler, et rotationsparameter samt et grabber pamameter.

	Der itereres gennem dette array. For hver led position oprettes et \texttt{JointTrajectoryPoint} objekt.  Dette består af det enkelte leds position, en velocity samt tiden, der går fra start af kommandoen.
	
Derefter lægges disse positioner ind i et \texttt{joinTrajectory} objekt, der udover disse indeholder navnene, der beskriver de enkelte joints).
Selve kommandoen til CrustCrawleren består af et goal, der indeholder joinTrajectory objektet samt en tidstolerance.
Dette mål sendes afsted til CrustCrawleren, hvorefter der afventes resultat. 

%%%%%%%%%%%%%% Section Pressure Sensor %%%%%%%%%%%%%%%%%
%\newpage
\section{Pressure sensor system}
For at kunne identificere, hvorvidt CrustCrawleren har grebet fat om en klods, er en tryksensor blevet anvendt. Denne sidder yderst på CrustCrawlerens griber. Til at tolke målingerne fra sensoren er en Arduino microcontroller blevet anvendt. Til kommunikation mellem Arduinoen og resten af systemet, er Rosserial bibliotiket blevet anvendt. 

\subsection{FSR 402 - Tryksensor}
Til måling af tryk bruges en Interlink FSR 402 Short. Denne fungerer ved at ændre modstanden over sensoren i forhold til det tryk, der lægges på den. Dette er en meget simpel sensor at anvende, da der udover sensoren blot skal anvendes en enkelt pull-down modstand. 

\figur{0.30}{FSRWiringDiagram.png}{Diagram over tilkobling af tryksensor til microcontroller}{fig:FSRWiringDiagram}

Som det ses på figur \ref{fig:FSRWiringDiagram}, er sensoren på det ene ben koblet til microcontrollerens 5v forsyning, og på det andet ben koblet til en 10 KOhm modstand, samt den pin, der rent faktisk måles på. Dette fungerer ved, at efterhånden som modstanden over FSR Sensoren falder, så mindskes den samlede modstand over FSR Sensoren og pull down modstanden. Dette medfører, at strømstyrken over begge modstande øges, og spændingen over den faste modstand stiger. Dermed øges spændingen også til den pin hvorpå målingen foretages. 

\subsection{Arduino - Microcontroller}
Som microcontroller er en Arduino UNO blevet anvendt. Valget faldt på denne, da den er let at anvende sammen med analoge sensorer, samt let at integrere med ROS, da der findes et officielt bibliotek til kommunikation mellem Arduino og ROS. 
Rosserial biblioteket anvendes til at oprette en node og publicere målinger. Til dette anvendes en nodehandler og en Publisher. 

\begin{lstlisting}[language=C]

//variables
ros::NodeHandle nh;
std_msgs::Int32 pressureMsg
ros::Publisher publisher("grabber_pressure", &pressureMsg);

void setup()
{
  // init node
  nh.initNode();

  // setup publisher
  nh.advertise(grabber_strain_gauge_publisher);
  
  //init serial comm
  Serial.begin(57600);
}

\end{lstlisting}

Læsning af sensoren og publicering af den læste data er meget simpel. Der foretages en læsning med \texttt{analogread()} metoden, der er en standard Arduino metode. Parametret der gives med er blot den pin, der foretages en læsning på. 
Denne læsning sendes med som data-attributten på den message, der publiceres. 

\begin{lstlisting}[language=C]

int checkStrain()
{
  return analogRead(strainGaugePin);
}

void publish(int val) {
	pressureMsg.data = val;
	publisher.publish(&pressureMsg);
}

\end{lstlisting}

For at få et kompromis mellem kontinuerlige data og spamming af beskeder, er der sat ti millisekunders delay mellem hver læsning og publicering af data. 

\subsection{Kommunikation med ROS}
Rosserial er som nævnt anvendt til kommunikation mellem microcontrolleren og resten af ROS systemet. Microcontrolleren skal dog stadig være sat til en pc, hvorpå en fuld ROS installation kører. Dette er nødvendigt, da Rosserial ikke i sig selv er en featurekomplet ROS installation, og derfor har brug for, at der fra pc siden initialeres en forbindelse til den. Dette gøres vha. følgende kommando. 

	\texttt{rosrun rosserial\_python serial\_node.py /dev/ttyACM0 \_baud:=57600}
	
	De sidste to argumenter specificerer henholdsvis den port, som microcontrolleren befinder sig på, og den baud rate, som forbindelsen skal oprettes med.










